{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "# import something as something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step One: the scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://redplanetscience.com\n"
     ]
    }
   ],
   "source": [
    "# scraping NASA Mars News\n",
    "# collect the latest News Title and Paragraph Text from redplanetscience.com and\n",
    "# save them to variables for use later.\n",
    "\n",
    "# <div class=\"content_title\">NASA's Mars Reconnaissance Orbiter Undergoes Memory Update</div>\n",
    "# div.content_title seems to be the latest news title.\n",
    "\n",
    "# <div class=\"article_teaser_body\">...</div>\n",
    "# div.article_teaser_body seems to be the paragraph text from the latest news title.\n",
    "\n",
    "# <div class=\"list_image\">...</div>\n",
    "# div.list_image seems to be the latest image, if that's fun.\n",
    "\n",
    "print(\"https://redplanetscience.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spaceimages-mars.com/\n"
     ]
    }
   ],
   "source": [
    "# scraping JPL Mars Space Images - Featured Image\n",
    "# visit spaceimages-mars.com.\n",
    "domain = \"https://spaceimages-mars.com/\"\n",
    "print(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spaceimages-mars.com/image/featured/mars3.jpg\n"
     ]
    }
   ],
   "source": [
    "# Use Splinter to navigate the site & find the URL of the current Featured Mars Image and\n",
    "# assign the url string to a variable called featured_image_url.\n",
    "# Find the URL of the *full size* .jpg image.\n",
    "# Save a complete url string for this image, e.g.\n",
    "# featured_image_url = 'https://spaceimages-mars.com/image/featured/mars2.jpg'\n",
    "\n",
    "# The current featured image seems to be\n",
    "# <img class=\"headerimage fade-in\" src=\"image/featured/mars3.jpg\">\n",
    "# featured_image_relative_url = somehow get what's in src out of the above\n",
    "featured_image_relative_url = \"image/featured/mars3.jpg\"\n",
    "featured_image_url = f\"{domain}{featured_image_relative_url}\"\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://galaxyfacts-mars.com\n"
     ]
    }
   ],
   "source": [
    "# scraping Mars Facts\n",
    "# visit galaxyfacts-mars.com\n",
    "print(\"https://galaxyfacts-mars.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://galaxyfacts-mars.com\n"
     ]
    }
   ],
   "source": [
    "# and use Pandas to scrape the table containing facts about the planet including:\n",
    "# diameter, mass, usw.\n",
    "# <table class=\"table table-striped\"> seems to be this table.\n",
    "#\n",
    "# Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://marshemispheres.com\n"
     ]
    }
   ],
   "source": [
    "# scraping Mars Hemispheres\n",
    "# Visit marshemispheres.com to obtain high resolution images for each of Mars's hemispheres.\n",
    "# Click each of the links to the hemispheres to find the URL of the full resolution image.\n",
    "# Save both the image url string for the full resolution hemisphere image,\n",
    "# and the Hemisphere title containing the hemisphere name.\n",
    "# Use a Python dictionary to store the data using the keys img_url and title.\n",
    "# Append the dictionary with the image url string and the hemisphere title to a list.\n",
    "# This list will contain one dictionary for each hemisphere.\n",
    "# Example:\n",
    "# hemisphere_image_urls = [\n",
    "#    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "#    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "#    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "#    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "# ]\n",
    "print(\"https://marshemispheres.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: MongoDB and Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://umn.bootcampcontent.com/University-of-Minnesota-Boot-Camp/uofm-stp-data-pt-12-2020-u-c/tree/master/02-Homework/12-Web-Scraping-and-Document-Databases/Instructions\n"
     ]
    }
   ],
   "source": [
    "# Use MongoDB with Flask templating to create a new HTML page\n",
    "# that displays all of the information that was scraped from the URLs above.\n",
    "\n",
    "# Start by converting your Jupyter notebook into a Python script called scrape_mars.py\n",
    "# with a function called scrape that will execute all of your scraping code from above\n",
    "# and return one Python dictionary containing all of the scraped data.\n",
    "\n",
    "# Next, create a route called /scrape that will import your scrape_mars.py script and\n",
    "# call your scrape function.\n",
    "\n",
    "# Store the return value in Mongo as a Python dictionary.\n",
    "\n",
    "# Create a root route / that will query your Mongo database and\n",
    "# pass the mars data into an HTML template to display the data.\n",
    "\n",
    "# Create a template HTML file called index.html that will take the mars data dictionary and\n",
    "# display all of the data in the appropriate HTML elements.\n",
    "# Use the following as a guide for what the final product should look like,\n",
    "# but feel free to create your own design.\n",
    "print(\"https://umn.bootcampcontent.com/University-of-Minnesota-Boot-Camp/uofm-stp-data-pt-12-2020-u-c/tree/master/02-Homework/12-Web-Scraping-and-Document-Databases/Instructions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the Jupyter Notebook containing the scraping code and\n",
    "# screenshots of your final application\n",
    "# to your GitHub repository and submit the link.\n",
    "# Ensure your repository has regular commits (i.e. 20+ commits) and\n",
    "# a thorough README.md file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Splinter to navigate the sites when needed and\n",
    "# BeautifulSoup to help find and parse out the necessary data.\n",
    "\n",
    "# Use Pymongo for CRUD applications for your database.\n",
    "# For this homework, you can simply overwrite the existing document each time\n",
    "# the /scrape url is visited and new data is obtained.\n",
    "\n",
    "# Use Bootstrap to structure your HTML template."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
